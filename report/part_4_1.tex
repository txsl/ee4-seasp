\documentclass[./main.tex]{subfiles} 
\begin{document}

\section{Widely Linear Filtering and Adaptive Spectral Estimation}

\subsection{Complex LMS and Widely Linear Modelling}

\subsubsection{The CLMS and ACLMS}
We are introduced to the Complex LMS, which is a modification of the LMS filter, but designed to operate with complex signals. The $ \mathbf{w}$ weight term is replaced with $ \mathbf{h}$, and the estimation is now $ \hat{y}(n) = \mathbf{h}^H(n) \mathbf{x}(n) $, with the weight update being performed as $ \mathbf{h}(n+1) = \mathbf{h}(n) + \mu e^{\ast}(n)\mathbf{x}(n) $.

We are also introduced to the Augmented CLMS, which is designed to identify the second order (if there is any) statistical relationship of the input and output. It is effectively an extension of the CLMS, and adds the weights $ \mathbf{g}$, in addition to $ \mathbf{h}$ as defined for the CLMS. The esimtation equation becomes  $ \hat{y}(n) = \mathbf{h}^H(n) \mathbf{x}(n) + \mathbf{g}^H(n) \mathbf{x}^\ast(n) $. The next estimated of $ \mathbf{g}$ is defined as $ \mathbf{g}(n+1) = \mathbf{g}(n) + \mu e^{\ast}(n)\mathbf{x}\ast(n) $.

We generated a WLMA(1) (Widely Linear Moving Average) process which is defined as $ y(n) = x(n) + b_1 x(n-1) + b_2 x^{\ast}(n-2) $, where $ x \sim \mathcal{N} (0,1) $. The coefficients are defined as $ b_1 = 1.5 + 1j $ and $ b_2 = 2.5 - 0.5j$. We run this process through both the CLMS and ACLMS filters. 100 indepdent sets of noise were generated and run through both filters (identical signals, to ensure a fair comparison), with the mean of at each iteration taken. Figure \ref{fig:4_1_a_clms_err} shows the learning error. We can see that even in steady state, there appears to be significant modelling error, sitting at 8dB. This is also apparent in figure \ref{fig:4_1_a_clms_weights} where we can see the estimated weights of $\mathbf{h}$. We are unable to see the values of coefficients related to $ b_2 $.

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\resizebox{\textwidth}{!}{\input{fig/4/4_1_a_clms.tikz}}
		\caption{\textit{Learning Curve of the filter, defined as $ 10 \log|e(n)|^2 $}}
		\label{fig:4_1_a_clms_err}
	\end{subfigure}
	~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
	%(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}[b]{0.49\textwidth}
	 \resizebox{\textwidth}{!}{\input{fig/4/4_1_a_clms_weights.tikz}}
		\caption{\textit{Esimated Weights (both real and imaginary components)}}
		\label{fig:4_1_a_clms_weights}
	\end{subfigure}
	\caption{\textit{Learning Curve and Estimated Weights from the CLMS fitler}}
\end{figure}

Figure \ref{fig:4_1_a_aclms} shows the same plots but this time from the ACLMS filter. We can immediately see that the learning curve in figure \ref{fig:4_1_a_aclms_err} is significantly better than those seen in figure \ref{fig:4_1_a_clms_err} with the CLMS filter. Since we are modelling an WLMA process, the output can be determined directly from the input (unlike with a `next step' estimator), so we expect the error to be very small. This is also evident in the weights in figure \ref{fig:4_1_a_aclms_weights}. We also observe that we can see 4 weights (the real and imaginary components of both $ \mathbf{g}$ and $ \mathbf{h}$), as opposed to the two seen in the CLMS. We can observe that the values associated with $ b_2 $ are represented by $ \mathbf{g} $.

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\resizebox{\textwidth}{!}{\input{fig/4/4_1_a_aclms.tikz}}
		\caption{\textit{Learning Curve of the filter, defined as $ 10 \log|e(n)|^2 $}}
		\label{fig:4_1_a_aclms_err}
	\end{subfigure}
	~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
	%(or a blank line to force the subfigure onto a new line)
	\begin{subfigure}[b]{0.49\textwidth}
		\resizebox{\textwidth}{!}{\input{fig/4/4_1_a_aclms_weights.tikz}}
		\caption{\textit{Estimated Weights (both real and imaginary components)}}
		\label{fig:4_1_a_aclms_weights}
	\end{subfigure}
	\caption{\textit{Learning Curve and Estimated Weights from the ACLMS fitler}}
	\label{fig:4_1_a_aclms}
\end{figure}

We can conclude that the CLMS was unable to represent the WLMA properly - the coefficients of $b_2$ which were from the conjugate of $\mathbf{x}$ were nowhere to be seen in the CLMS, but very clear in the ACLMS. The fact that the learning curve of the CLMS showed a large steady state error is evidence that the model was a poor fit for the CLMS.

\subsubsection{Bivariate Wind Data}

We are given wind data for a slow, medium and high wind regime. The data contains wind East-West wind speeds, as well as North-South wind speeds for a given point in time. We represent these in complex form, as $ v[n] = v_{east}[n] + jv_{north}[n] $. 

%\begin{figure}[h]
%	\centering 
%	\resizebox{\textwidth}{!}{\input{fig/4/4_1_b_circularity.tikz}}
%	\caption{\textit{}}
%	\label{fig:4_1_b}
%\end{figure}


% \begin{equation}
% S = \frac{1}{N}X' X'^T
% \end{equation}


%  \begin{figure}[h]
%  	\centering 
% 	\resizebox{0.6\textwidth}{!}{\input{q5/q5_cum.tikz}}
%   	\caption{\textit{Cumulative representation of the variance of each eigenvector}}
%   	\label{fig:q5_4}
%  \end{figure}

% \begin{figure}[h]
% 	\centering 
%  	\setlength\figureheight{0.4\textwidth}
% 	\setlength\figurewidth{0.7\textwidth} 
%  	\input{p_1/1.tikz}
%  	\caption{\textit{The four randomly generated subsets}}
%  	\label{fig:q1}
% \end{figure}


%  \begin{figure}[h]
%          \centering
%          \begin{subfigure}[b]{0.45\textwidth}
%             \resizebox{\textwidth}{!}{\input{part_4/q8_num_1.tikz}}
%   			\caption{\textit{1 Tree}}
%          \end{subfigure}
%          ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%           %(or a blank line to force the subfigure onto a new line)
%          \begin{subfigure}[b]{0.45\textwidth}
%             \resizebox{\textwidth}{!}{\input{part_4/q8_num_3.tikz}}
%   			\caption{\textit{2 Trees}}
%          \end{subfigure}
 		
%          \begin{subfigure}[b]{0.45\textwidth}
%             \resizebox{\textwidth}{!}{\input{part_4/q8_num_5.tikz}}
%   			\caption{\textit{5 Trees}}
%          \end{subfigure}
%          ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
%           %(or a blank line to force the subfigure onto a new line)
%          \begin{subfigure}[b]{0.45\textwidth}
%             \resizebox{\textwidth}{!}{\input{part_4/q8_num_10.tikz}}
%   			\caption{\textit{10 Trees}}
%          \end{subfigure}
         
%          \begin{subfigure}[b]{0.45\textwidth}
%             \resizebox{\textwidth}{!}{\input{part_4/q8_num_20.tikz}}
%   			\caption{\textit{20 Trees}}
%          \end{subfigure}
 		
%  		\label{q9i}
% 		\caption{\textit{Varying the Number of Trees in the Forest}}
%  \end{figure}

\end{document}

